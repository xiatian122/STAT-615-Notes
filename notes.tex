% Use only LaTeX2e, calling the article.cls class and 12-point type.

\documentclass[12pt]{article}

% Users of the {thebibliography} environment or BibTeX should use the
% scicite.sty package, downloadable from *Science* at
% www.sciencemag.org/about/authors/prep/TeX_help/ .
% This package should properly format in-text
% reference calls and reference-list numbers.

\usepackage{scicite}

% Use times if you have the font installed; otherwise, comment out the
% following line.

\usepackage{times}

% The preamble here sets up a lot of new/revised commands and
% environments.  It's annoying, but please do *not* try to strip these
% out into a separate .sty file (which could lead to the loss of some
% information when we convert the file to other formats).  Instead, keep
% them in the preamble of your main LaTeX source file.


% The following parameters seem to provide a reasonable page setup.

\topmargin 0.0cm
\oddsidemargin 0.2cm
\textwidth 16cm 
\textheight 21cm
\footskip 1.0cm


%The next command sets up an environment for the abstract to your paper.

\newenvironment{sciabstract}{%
\begin{quote} \bf}
{\end{quote}}


% If your reference list includes text notes as well as references,
% include the following line; otherwise, comment it out.

\renewcommand\refname{References and Notes}

% The following lines set up an environment for the last note in the
% reference list, which commonly includes acknowledgments of funding,
% help, etc.  It's intended for users of BibTeX or the {thebibliography}
% environment.  Users who are hand-coding their references at the end
% using a list environment such as {enumerate} can simply add another
% item at the end, and it will be numbered automatically.

\newcounter{lastnote}
\newenvironment{scilastnote}{%
\setcounter{lastnote}{\value{enumiv}}%
\addtocounter{lastnote}{+1}%
\begin{list}%
{\arabic{lastnote}.}
{\setlength{\leftmargin}{.22in}}
{\setlength{\labelsep}{.5em}}}
{\end{list}}

\usepackage{amsthm}
\usepackage{thmtools}
\usepackage{enumerate}
\usepackage{amsfonts}
\usepackage{nth}
\usepackage{stackrel}
\usepackage{bbm}
\usepackage{amsmath}


\theoremstyle{definition}
\newtheorem{mydef}{Definition.}[section]
\newtheorem{myexp}{Example.}[section]

\theoremstyle{plain}
\newtheorem{mythm}{Theorem}[section]


\setcounter{section}{-1}
\pagenumbering{arabic}

% Include your paper's title here

\title{ Introduction to Stochastic Process\\ STAT 615 Course Notes} 


% Place the author information here.  Please hand-code the contact
% information and notecalls; do *not* use \footnote commands.  Let the
% author contact information appear immediately below the author names
% as shown.  We would also prefer that you don't change the type-size
% settings shown here.

\author
{Daren Cline,$^{1\ast}$\\
\\
\normalsize{$^{1}$Department of Statistics, Texas A\&M University,}\\
\normalsize{College Station 77843-3143, USA}\\
\normalsize{ E-mail:  dcline@stat.tamu.edu.}
\\
\normalsize{Input by Tian Xia; Email: tianxia@cse.tamu.edu}
}

% Include the date command, but leave its argument blank.

\date{}



%%%%%%%%%%%%%%%%% END OF PREAMBLE %%%%%%%%%%%%%%%%



\begin{document} 

% Double-space the manuscript.

\baselineskip24pt

% Make the title.

\maketitle 



% Place your abstract within the special {sciabstract} environment.

\begin{sciabstract}
 
\end{sciabstract}




\section{Preliminaries}
\begin{mydef}
A \underline{\textbf{sample space}} $\mathbf{\Omega}$ is the collection of individual \underline{outcomes} or \underline{realizations} for a random experiment. \\
Subsets of $\mathbf{\Omega}$ are called \underline{events}. For $A \subset \mathbf{\Omega}$, we say ``A occurs'' if the outcome $\omega \in A$ 
\end{mydef}

$\Omega$ can be \underline{countable} (finite or countably infinite) or \underline{uncountable}. It need not consisit of real-valued entities. Most often, its role is in the background and simply assured.

\begin{myexp}
Toss a coin infinitely many times, observing $1$ (heads) or $0$ (tails) for each toss. The outcomes are inifinite sequences of $0$'s \& $1$'s, such as $(1,1,0,0,0,1, \cdots)$. The collection $\mathbf{\Omega}$ of all possible outcomes is uncountable in this case.
\end{myexp}
Events are subsets of $\mathbf{\Omega}$, often identified descriptively:
\begin{itemize}
\item ``\nth{1} toss is H''$=\{(x_1, x_2, \cdots):x_1 = 1\}$.
\item ``12 H's in the \nth{1} 100 tosses''  $=\{(x_1, x_2, \cdots): \sum_{i=1}^100 x_i = 12\}$.
\item ``the long tem proportion of H's is $\frac{1}{3}$''  =  $\{(x_1, x_2, \cdots):\frac{1}{n}\sum_{i=1}^n x_i \rightarrow \frac{1}{3}\}$.
\end{itemize}
A \underline{singleton} event is a subset of just one outcome, which is not quite the same as the outcome itself. \\
The empty set $\phi$ is considered to be an event also.

\begin{mydef}
A \underline{\textbf{probability measure}} $P$ is a set function (i.e. $P$ is applied to events, not to outcomes) such that
\begin{enumerate}[(i)]
\item $0 \leq P(A) \leq 1$, with $P(\mathbf{\Omega}) = 1, P(\phi) = 0$
\item if $A_1, A_2, \cdots$ are \underline{disjoint} then $P(\bigcup_{i=1}^\infty A_i) = \sum_{i=1}^\infty P(A_i)$ (similarly for finite unions) 
\end{enumerate}
\end{mydef}
when the $A_i$'s are not disjoint, we have
\begin{mythm}
(Boole's inequality) \[P(\bigcup_{i=1}^n A_i) \leq \sum_{i=1}^n P(A_i)\].
\end{mythm}

\begin{mydef}
A collection of $\mathbf{A}$ of subsets of $\mathbf{\Omega}$ is called a \underline{$\mathbf{\sigma}$\textbf{-algebra}} (or $\sigma$-field) if 
\begin{enumerate}[(i)]
\item $\phi, \mathbf{\Omega} \in \mathbf{A}$
\item $A \in \mathcal{A} \Longrightarrow   A^{\mathrm{c}} \in \mathcal{A}$
\item $A_1, A_2, \cdots \in \mathcal{A} \Longrightarrow \bigcup_{i=1}^\infty A_i \in \mathcal{A}$  (Some for finite unions) and hence also $\bigcap_{i=1}^\infty \in \mathcal{A}$ 
\end{enumerate}
\end{mydef}
\textbf{Note:} the requirement is closure under \underline{countable} unions and intersections. So a union of uncountably may subsets in $\mathcal{A}$ need not itself be in $\mathcal{A}$. (there are important mathematical reasons for allowing this.)
\textbf{Additional Note:} \underline{complement} $A^\mathcal{c}=$''A does not occur''
union of events $\bigcup_i A_i = $ ``some $A_i$ (at least one) occurs''
intersection $\bigcap_i A_i=$ ``every $A_i$ occurs'' 

\begin{myexp}
If $\mathbf{\Omega}$ is countable (such as the integers $\mathbb{Z}$) then we can let $\mathcal{A}$ be all subsets.
\end{myexp}
\begin{myexp}
If $\Omega = \mathbb{R}$ (all real values), we usually use the \underline{\textbf{Borel Sets}} $B=$ smallest $\sigma$-algebra that contains all singletons and all intervals. So $\mathcal{B}$ would include countable unions of intervals, but this by no means comes close to all it has. There is no direct formula or description to characterize all arbitrary Borel sets.\\
On the other hand, given $B \in \mathcal{B}$ and a probability measure $P$, $P(B)$ can be approximated as close as we like with the probability of some finite union of intervals.
\\ 
Borel sets on $\mathbb{R}^\mathrm{d}$ (d-dimensional vectors) are defined similaryly, using \underline{rectangles}.
\end{myexp}

\begin{myexp}
(cond.) Let $\Omega = \{(x_1, x_2, x_3, \cdots): x_i = 0$ or $x_i = 1$ for each $i \geq 1\}$ be the sample space of infinite sequences of coin tosses by \underline{cylinder events} (events where a \underline{finite} number of the $x_i$'s are fixed). For example, \[\{(x_1, x_2, \cdots) : x_1 = 1, x_2 = 0\}\].
\end{myexp}
The triple $(\Omega, \mathcal{A}, P)$ (i.e. sample space, $\sigma$-algebra of events probability measure) is called a \underline{probability space}. 

\begin{mydef}
A \underline{\textbf{random variable}} $X = X(\omega)$ is a real-valued function applied to outcomes (i.e., $X: \Omega \rightarrow \mathbb{R}$. \\
An \underline{extended random variable} can possibly take infinite values (i.e., $X: \Omega \rightarrow \bar{\mathbb{R}} \stackrel{def}{=} \mathbb{R} \vee \{-\infty, \infty\}$ (``$\stackrel{def}{=}$'' means ``defined as'', the same as ``$=:$''))
\end{mydef}


Since random variables (rvs) are functions, it is \underline{highly recommended} that you take care to distinguish them from actual (possible) values. We will usually, but not always, use upper case for rvs and lower case for actual values. (Also, try to avoid using the same name, such as $X$ or $Y$, for everything, and centatinly make distinctions between rvs in the same problem/context.) 

A \underline{random vector} is a vector of rvs and a \underline{random (stochastic) process} is a sequence of rvs (e.g. $(x_1, x_2, \cdots)$) or a function that takes random values (e.g. $x(t), t \in \mathbb{R}$, where each $X(t)$ is a random variable).

\begin{mydef}
Every rv $X$ has a \underline{cululative distribution function} (cdf) \[F_X(x) = P(X \leq x)\] (sensible even for extended rvs)
\end{mydef}

A rv $X$ (or its cdf) is \underline{discrete} if there is a countable set of values $\{a_i\}$ such that $\sum_i P(x = a_i) = 1, \{P_i\}=\{P(x = a_i)\}$ is called the \underline{probability mass function} (pmf). 

A rv $X$ (or its cdf) is \underline{absolutely continuous} if \[P(a < X \leq b) = F(b) - F(a) = \int_a^b f(x)dx\] for some function $f(x)$, called the \underline{probability density function} (pdf) 

\underline{However}, we do not with to limit ourselves to just two types. There are, for example, rvs with neither a pmf or a pdf, and these are mixtures of types. Things become more general still for random vectors. 

Furthermore, a stochastic process cannot be characterized so simply at all (More on this in the \nth{1} chapter). 

We will write $X \sim F_X$ (or $X \sim \{P_i\}$ or $X \sim f(x)$ when the context is clear) to signify that $X$ has distribution given by $F_x$. \\
\\
You should be familiar with all the commonly used distributions.
\begin{itemize}
\item ex. $Y \sim Poisson(\lambda)$ with pmf \[P(y = k) = \frac{\lambda ^k e^{- \lambda}}{k!}, k = 0, 1, 2, \cdots\].
\item ex. $T \sim Gamma(\alpha, \beta)$ with pdf \[f(t) = \frac{\beta ^ \alpha t^{\alpha - 1}e^{-\beta t}}{\Gamma (\alpha)}, t \geq 0\].
\end{itemize}

\begin{mydef}
Random variables $X_1, \cdots, X_m$ are \underline{independent} if \[P(X_1 \in A_1, X_2 \in A_2, \cdots, X_m \in A_m) = \prod_{i=1}^m P(X_i \in A)\] for all \textbf{Borel sets} $A_1, \cdots, A_m$. \\
Equivalently, \[P(X_1 \leq x_1, \cdots, X_m \leq x_m) = \prod_{i=1}^m P(X_i \leq x_i)\] for all real values $x_1, \cdots, x_m$. \\
(The \nth{1} definition can be applied to random elements of any kind, with appropriate $A_i$'s.)
\end{mydef}

A collection $\{X_t\}$ of rvs (possibly uncountably many) is \underline{independent} if every finite sub-collection is. That is, if $X_{t_1}, \cdots, X_{t_m}$ are independent, for any $t_1, \cdots, t_m$. \\ 

A sequence $\{X_n\}$ is \underline{independent and identically distributed} (iid) if it is independent and all the rvs have the same distribution. We sometimes write $\{X_n\} \stackrel{iid}{\sim} F$ (or just $X_n \stackrel{iid}{\sim} F$) . \\ 

Stochastic processes are generally \underline{not independent} (they wouldn't be interesting if they were). But they often can be constructed or described in terms of independent rvs. \\ 

Random variables and their distributions can also be characterized in terms of expectations. As before, we do not wish to be limited to special types (and in fact it is notationally more convenient not to be).

\begin{mydef}
Here is how the expectation $E(g(x))$ is defined (if possible).\\
For simplicity, just let $Y = g(X)$ and we'll define $E(Y)$.
\begin{enumerate}
\item \underline{indicator rv} \\ 

if 
\begin{displaymath}
Y = \mathbbm{1}_A = \begin{cases}
0, & \text{if A does not occur} \\
1, & \text{if A does occur}
\end{cases}
\end{displaymath}
then \[E(\mathbbm{1}_A) = P(A)\]. indicator rvs have \underline{Bernoulli distribution} (which simply means discrete on $\{0,1\}$)

\item \underline{simple rv} \\
Y is a finite linear combination of indicator rvs \\
i.e. $Y = \sum_{i=1}^m c_i \mathbbm{1}_{A_i}$ (hence discrete w/ finitely many values) \\
 then \[E(Y) = \sum_{i=1}^m c_i P(A_i)\]. (this works even if the $A_i$'s are not disjoint or if the $c_i$'s are not distinct.)
 
 \item \underline{nonnegative rv} \\ 
  $Y \geq 0$. There always exist nonnegative simple rvs $Y_n(\omega) \mathbbm{\uparrow} Y(\omega)$ for every $\omega \in \Omega$. \\
 Then \[E(Y) = \lim \limits_{n \rightarrow \infty} E(Y_n) \quad  \text{(which myght equal $\infty$)}\] 
 ( This does not depend on the choice of sequenc $\{Y_n\}$, nor is it necessarily the best way to \underline{compute} $E(y)$. )

\item \underline{general rv $Y$} \\
Define the positive part of $Y$, $Y_+ = \max(Y,0)$\\
and the negative part, $Y_- = \max(-Y, 0)$. \\
(both are nonnegative) \\
so $Y = Y_+ - Y_-$ and $|Y| = Y_+ + Y_-$\\
Then if either (or both) of $E(Y_+) \& E(Y_-)$ are finite, define \[E(Y) = E(Y_+)-E(Y_-)\]. (Again, the value can be infite - we just don't allow the case $\infty$ $-\infty$)
\end{enumerate}
\end{mydef}

The purpose of the above is just so we can define ( and talk about) expectations without having to worry about the type of rv or how the expectation is to be computed. In fact, computing expectations will depend on context and often is not necessary in specific cases.

\begin{mydef}
(Lebesque-Stielties notation). \\
If $X \sim F$, it is conventional to express \[E(x) = \int_{-\infty}^{\infty} x F(dx)\], and $E(g(x)) = \int_{-\infty}^{\infty}g(x)F(dx)$, when they can be defined. \\
A similar usage applies to random vectors, using a \underline{joint cdf} (but not to stochastic processes) .
\end{mydef}
$\mbox{}$\\
Other terminology. 
\begin{itemize}
\item A random variable $X$ is \underline{finite} if $|X(\omega)| < \infty$ for \underline{all} $\omega \in \Omega$. 
\item A random variable $X$ is \underline{bounded} if there exists a constant $C$ such that $|X(\omega)| \leq C$ for all $\omega \in \Omega$. 
\item Do not confuse ``finite'' \& ``bounded''. 
\end{itemize}

The terms apply in similar fashion to any real valued function $g(x)$.  \\ \\
An event $A$ occurs \underline{almost surely} (a.s.) or \underline{with probability 1} (w.p.1) if P(A) = 1. \\ 
Note that ``almost sure'' is in the context of a specific probability measure or model, whereas the definition of $A$ (as some event) is not. 

ex. $Y$ is almost surely finite if $P(|Y| < \infty) = 1$. However, the event $\{Y = \infty\}$ need not be empty. Indeed, we will want to discuss rvs taht are almost surely finite for some models but not for others ( and to identify the distinguishing condition ) . 

ex. $X_n$ converges to $X$ almost surely ($X_n \rightarrow X$ a.s.), if $P(\lim \limits_{n \rightarrow \infty}X_n = X) = 1$, \\
This is stronger than convergence in probability:  $P(|X_n - X| > \epsilon) \rightarrow 0$ for all positive $\epsilon$.


\subsection*{The basic limit theorems}
\begin{mythm}
\underline{\textbf{Monotone Convergence}} (MCT) \\
For $0 \leq X_n \mathbbm{\uparrow} X : E(X_n) \rightarrow E(X)$ (even if infinite) \\
Likewise, if $0 \leq g_n(x) \mathbbm{\uparrow} g(x)$ for all $x$, then \[\int g_n(x) dx \rightarrow \int g(x) dx\], and \[\sum_{i=1}^\infty g_n(i) \rightarrow \sum_{i=1}^\infty g(i) \]
\end{mythm}
\begin{mythm}
\underline{\textbf{Dominated Convergence}} (DCT) \\
For $X_n \rightarrow X$ such that $|X_n| \leq Y$ and $E(y) < \infty$, $E(X_n) \rightarrow E(X)$.\\
(again, similar statements for integrals \& sums)
\end{mythm}
\begin{mythm}
\underline{\textbf{Fatou's Lemma}} $X_n \geq 0, X_n \rightarrow X$ \[ \liminf \limits_{n \rightarrow \infty} E(X_n) \geq E(X)\] ( \& similarly for sums and integrals)\\
( Note: \[\liminf \limits_{n \rightarrow a_n} = \lim \limits_{n \rightarrow \infty} (\underset{k \geq n}{\inf} a_k) \quad \& \quad \limsup \limits_{n \rightarrow \infty} a_n = \lim \limits_{n \rightarrow \infty} (\underset{k \geq n}{\sup} a_k)\]. )
\end{mythm}
\begin{mythm}
\underline{\textbf{Strong Law of Large Numbers}} (SLLN) For iid $X_n$, \[\frac{1}{n}\sum_{i=1}^n X_i \rightarrow E(X) \qquad \text{(if defined)}\] almost surely, and \[E(|\frac{1}{n}\sum_{i=1}{n}X_i - E(X)|) \rightarrow 0 \quad \text{(if $E(|x|) < \infty$})\].
\end{mythm}

\subsection*{Equalities \& inequalities}

\begin{mythm}
$\mbox{}$
\begin{itemize}
\item If $X \geq 0$ then $E(X) = \int_0^\infty P(X > x)dx$, even if infinite (\& valid even if $P(X=\infty)>0$). 
\item If $X \geq 0$ and is integer-valued then \[E(X) = \sum_{n=0}^{\infty}P(X > n)\]
\end{itemize}
\end{mythm}

\begin{mythm} 
$\mbox{}$
\begin{enumerate}[(i)]
\item (Markov) If $g(x) \geq 0$ \& nondecreasing then \[P(X \geq x) \leq \frac{E(g(X))}{g(x)}\]  e.g. \[P(|X| >x) \leq \frac{E(|x|)}{x} \quad \& \quad P(|X| > x) \leq \frac{E(x^2)}{x^2}\].
\item $|E(x)| \leq E(|x|)$
\item (Lyapunov) $E(|X|^r) \leq (E(x^2)E(y^2))^{\frac{1}{2}}, \quad \text{if $0 < r <s$}$.
\item (Cauchy-Schwaiz) $|E(xy)| \leq (E(x^2)(y^2))^{\frac{1}{2}}$
\item (Jenson) If $g(x)$ is convex then $E(g(x)) \geq g(E(x))$ with equality only if $g(x)=a + bx$ for some constants $a,b$. \\
Note: ``convex'' means $g(ax+(1-a)y) \leq ag(x) + (1-a)g(y),0 < a < 1$ \\
Equivalently, $g(b) - g(a) = \int_{a}^{b}g'(u)du$ all $a,b$ and $g'(u)$ is nondecreasing (the derivative need not exist at all values of $u$ for this to hold)
\end{enumerate}
\end{mythm}
\begin{mythm}
(Kolmogorov maximal inequality) \\
If $X_n$ are independent, each $E(X_n^2) < \infty \quad \& \quad S_n = X_1 + \cdots + X_n$ \\
then \[P(\underset{k \leq n}{\max}|S_k - E(S_k)| > x) \leq \frac{\mathrm{Var}(S_n)}{x^2}\]
\end{mythm}
The next result takes many guises, but you should set the idea from examples shown.

\begin{mythm}
(Fubini-tonelli) \\
Suppose either that $g(x,y) \geq 0$ for all $x,y$ or the quantities below are \underline{finite} when $g(x,y)$ is replaced with $|g(x,y)|$.
\begin{enumerate}[(i)]
\item \[\iint g(x,y)dxdy = \iint g(x,y)dydx\].
\item \[\int \sum_{n=0}^\infty g(n,y)dy = \sum_{n=0}^\infty \int g(n,y) dy\].
\item \[\int E(g(X,y))dy = E(\int g(x,y)dy)\].
\item \[\sum_{n=0}^\infty E(g(X,n)) = E(\sum_{n=0}^\infty g(X,n))\].
\item \[\sum_{n=0}^\infty \sum_{k=0}^\infty g(n,k) = \sum_{k=0}^\infty \sum_{n=0}^\infty g(n,k)\].
\item \[\iint g(x,y)F(dx)G(dy) = \iint g(x,y)G(dy)F(dx)\], where the latter are lebesgue-stieltjes integrals. (When $g(x,y) \geq 0$ all $x,y$ the double integrals/sums/etc above can equal $\infty$, on both sides.)
\end{enumerate}
\end{mythm}

We rely heavily on conditional probabilities and conditional expectation. Like expectation, however, we want to discuss \& use them without being restricted to joint discrete distributions or joint continuous distributions. We provide here, without elaboration, a suitably general definition.

\begin{mydef}
Let $Y$ be a r.v. such that $E(Y)$ exists, and $X$ be a random element (r.v., r. vector, stochastic process). The \underline{conditional expectation} of $Y$ given $X$, denoted $E(y|X)$ is\\
a function of the random variable $X$, say $h(x)$, (Note: this also means $E(Y|X)$ is itself a r.v.) such that \[E(g(x)Y) = E(g(x)E(Y|X)) \qquad \text{(*)}\] for all (measurable) bounded real-valued functions $g(x)$. (``measurable'' just means $\{x:g(x) \leq y\}$ is a Borel set, which is a technical restriction not usually of much concern to us.)
\end{mydef}
Conditional Probability $P(y\in A | X) = E(\mathbbm{1}_A(y)|X)$. 

The definition \underline{does not} tell us how to compute $E(y|X)$; it merely says that we can define it.\\
Note that $E(y|X)$ is \underline{a random variable} (but it must be a function of $X$) . Often we may have a way to define or compute $h(x)=E(y|X=x)$ suitably and then set $E(y|X) = h(X)$.

\subsection*{Properties of conditional expectation}
\begin{mythm}
Given $X$, and r.v.'s $Y, Y_1, Y_2, \cdots$ (w/ means)
\begin{enumerate}[(i)]
\item $Y_1 \leq Y_2 \implies E(Y_1|X) \leq E(Y_2|X)$.
\item $E(aY_1 + bY_2|X) = aE(Y_1|X) + bE(Y_2|X)$.
\item MCT, DCT \& Fatou's lemma all hold, cond. on $X$.
\item The formula (*) in \textbf{Theorem.0.6.} holds whenever whenever the expectations exist (not just for bounded $g(x)$).
\item (Pull-Out) $E(g(x)y/X) = g(X) E(y|x)$, if it exists.
\item (In)equalities for expectation (Jensen, etc.) all hold, cond. on $X$.
\item If $Y$ is independent of X then $E(Y|X) = E(Y)$.
\item $y=h(x)$ then $E(y|x) = y$
\item (Tower) $E(y|x)=E(E(y|x,z)|x) = E(E(y|x)|x,z)$.
\end{enumerate}
Basically, we can work with conditional expectations in an intuitive fashion based on familarity with definitions for the case $(x,y)$ is jointly discrete or jointly absolutely cont. \\
But now we can do so without those restrictions, including the case $X$ is a stochastic process (or a portion of one) consisting of infinitely many rv's.
\end{mythm}
Take care to use the tower property, (ix) above, correctly. It is \underline{not} usually true that \[E(E(y|x)|z) = E(E(y|z)|x)\] 

One other caution: $E(y|x)$ is not originly defined since $P(b{x}=0)=1$ implies $E(y|x) + b(x)$ also satisfies the definition. We don't usually have a problem w/ this if there are only countably many r.v.s.

\newpage

\section{Introduction}
\begin{itemize}
\item definitions
\item examples (simple random walk, simple branching proc.)
\item probability generating functions
\item some analytic results
\end{itemize}

\begin{mydef}
A \underline{\textbf{stochastic process}} is a collection of random variables, $\{X_t\}_{t \in \mathbbm{T}}$, defined on the same probability space. The \underline{state space} $\mathbbm{X}$ is a set of possible values for $X_t$ and the \underline{index set} $\mathbbm{T}$ is the set on which $X_t$ evolves.\\
(a single instance of values $\{X_t\}$ is called a \underline{sample path}.) \\
For us, $\mathbbm{X}$ will usually be the integers $\mathbbm{Z}$ or the real line $\mathbbm{R}$ (or some other subset of $\mathbbm{R}$ but it can be $\mathbbm{R}^m$ or something more exotic. \\
$\mathbbm{T}$ will usually be the nonnegative integers $\mathbbm{Z}_+$ or the nonnegative real numbers $\mathbbm{R}_+ = [0, \infty)$, but it also can be more general. 
\end{mydef}

\begin{myexp}
$X_t=\#$ of people infected on day $t$ of an epidemic \\
$X_{s,t}=$ temperature at point $s$ on the globe and time $t$ \\
$X(A)=\#$ of fireant colonies in a region $A$ (here $\mathbbm{T}$ is a collection of sets, including all open \& closed sets)
\end{myexp}
$\mbox{}$\\
Stochastic processes have many applications: \\
e.g. signal process, random networks, queues, climate, earthquakes, insect populations, stock market, economics, epidemics, and so on. \\ \\
\textbf{Note}: I generally use upper case for random variables and lower case for actual values.\\ \\
Just as we do for a random variable \& a  random vector, we want to discuss the \underline{distribution} of a stochastic process. But, with infinitely many rv's, we cannot simply express it as an ordinary function (such as a cdf). Instead we have 

\bibliography{scibib}

\bibliographystyle{Science}





\clearpage




\end{document}




















